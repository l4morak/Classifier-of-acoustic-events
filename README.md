# Classifier of Acoustic Events
Решение задачи "Классификатор акустических событий". (файл main.py)

Лучшая точность на известных объектах test выборки - 86 % (Accuracy Score); 97.5 % (ROC AUC Score - усредненная, вычисленная по отдельности для каждого отдельного класса); 87 % (Mean Average Precision).  

Модель использует предобученные сверточные слои модели VGGish. 
(https://github.com/tensorflow/models/tree/master/research/audioset - ссылка на оригинальный источник)
(https://github.com/DTaoo/VGGish - VGGish на Keras)  
Результаты VGGish передаются сети с тремя слоями. (800 нейронов, дропаут, 800 нейронов, дропаут, ReLU, 8 нейронов, Softmax)

Для расчета конечного результата используются 10 одинаковых сетей, берется среднее арифметическое их предсказаний. Это сделано из-за того, что конечный результат после обучения модели может сильно отличаться на 5-8 % в худшую сторону.

Для запуска разместите внутри одной папки две папки: audio/, test/.
В файле main.py значение переменной root_dir замените на путь к этой папке. Также в той же папке поместите веса VGGish. (https://drive.google.com/open?id=16JrWEedwaZFVZYvn1woPKCuWx85Ghzkp)  

P.S. Рекомендуется использовать GPU. Этап, связанный с VGGish, затягивается на процессоре минут на 5.  
P.P.S Результаты немного улучшились. Заметил опечатку в коде.
